---
title: 芹菜学习笔记一
tags: 
- python
- 编程
date: 2017-12-11
category: 编程
---

> 最近开始学习芹菜，刚开始看的时候一头雾水，不知道怎么使用，主要是把基本的几个概念搞清楚以后，就能理解芹菜的工作原理。本文是第一部分介绍，所以内容相对简单。
>
> 使用环境： python 3.5

<!--more-->

# 消息中间件 broker

broker其实就是一个任务队列。常用的broker有

`redis` , `rabbitmq` 或者相关数据库

| **名称**       | **状态** | **监视** | **远程控制** |
| ------------ | ------ | ------ | -------- |
| *RabbitMQ*   | 稳定     | 是      | 是        |
| *Redis*      | 稳定     | 是      | 是        |
| *Mongo DB*   | 实验性    | 是      | 是        |
| *Beanstalk*  | 实验性    | 否      | 否        |
| *Amazon SQS* | 实验性    | 否      | 否        |
| *Couch DB*   | 实验性    | 否      | 否        |
| *Zookeeper*  | 实验性    | 否      | 否        |
| *Django DB*  | 实验性    | 否      | 否        |
| *SQLAlchemy* | 实验性    | 否      | 否        |
| *Iron MQ*    | 第三方    | 否      | 否        |



# backend与worker

* backend 其实就是数据库，用来存储消息和消息执行的结果，比如任务是否执行的状态，以及执行的结果等信息。
* worker 其实就是`独立的职程进程持续监视队列中是否有需要处理的新任务`

backend 用什么类型的数据库都可以，只是用来存储结果信息。



# 上手

## 安装redis-server

```sql
$ sudo apt-get install redis-server
```

windows 用户自行下载安装，并启动运行。Linux用户安装以后默认运行。

确保安装了`redis-server`环境，并且启动了，默认监听`6379` 端口



## 安装redis和 celery 模块

```sql
$ sudo pip install redis celery
```



## 上代码

此处`broker`和`backend`都使用`redis`，分别使用数据库`1`和`2`.

```python
# tasks.py
from celery import Celery

CELERY_BROKER = "redis://localhost:6379/1"
CELERY_BACKEND = "redis://localhost:6379/2"

app = Celery("tasks", backend=CELERY_BACKEND,
             broker=CELERY_BROKER)


@app.task
def add(x: int, y: int): # 低于python 3.5 更改为def add(x, y):
    return x + y

```

启动芹菜任务

```shell
vinct@vinct:~/Documents/pyhome/learn$ celery -A tasks worker --loglevel=info
 
 -------------- celery@vinct v4.1.0 (latentcall)
---- **** ----- 
--- * ***  * -- Linux-4.8.0-52-generic-x86_64-with-Ubuntu-16.10-yakkety 2017-10-07 17:14:14
-- * - **** --- 
- ** ---------- [config]
- ** ---------- .> app:         tasks:0x7f9ca309d828
- ** ---------- .> transport:   redis://localhost:6379/1
- ** ---------- .> results:     redis://localhost:6379/2
- *** --- * --- .> concurrency: 4 (prefork)
-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
--- ***** ----- 
 -------------- [queues]
                .> celery           exchange=celery(direct) key=celery
                

[tasks]
  . tasks.add

[2017-10-07 17:14:14,415: INFO/MainProcess] Connected to redis://localhost:6379/1
[2017-10-07 17:14:14,421: INFO/MainProcess] mingle: searching for neighbors
[2017-10-07 17:14:15,436: INFO/MainProcess] mingle: all alone
[2017-10-07 17:14:15,450: INFO/MainProcess] celery@vinct ready.
```

启动 ipython并添加任务

```python
vinct@vinct:~/Documents/pyhome/learn$ ipython
Python 3.5.2+ (default, Sep 22 2016, 12:18:14) 
Type "copyright", "credits" or "license" for more information.

IPython 5.3.0 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.

In [1]: from tasks import add

In [2]: add(2, 8)
Out[2]: 10
    
In [3]: add.delay(2, 9)
Out[3]: <AsyncResult: 46a67c8f-d699-412d-8647-cfa700830cd2>

In [4]: add.delay(2, 100)
Out[4]: <AsyncResult: 8b9910c2-be8f-42cc-9190-34bed2addcef>

In [5]: add.delay(100, 19)
Out[5]: <AsyncResult: 2b36858c-90cb-4da7-8000-de877c63f546>

In [6]: add.delay(100, 19)
Out[6]: <AsyncResult: 7281b2da-636e-4ce9-8a26-19247db674dc>

In [7]: add.delay(100, 100000)
Out[7]: <AsyncResult: 4e775e36-8fbc-43cc-81dd-f1a9aae74486>
```

可以看到芹菜后台很快接收到任务，并处理任务

```shell
[2017-10-07 17:15:26,601: INFO/MainProcess] Received task: tasks.add[46a67c8f-d699-412d-8647-cfa700830cd2]  
[2017-10-07 17:15:26,605: INFO/ForkPoolWorker-4] Task tasks.add[46a67c8f-d699-412d-8647-cfa700830cd2] succeeded in 0.0031327969991252758s: 11
[2017-10-07 17:15:52,416: INFO/MainProcess] Received task: tasks.add[8b9910c2-be8f-42cc-9190-34bed2addcef]  
[2017-10-07 17:15:52,420: INFO/ForkPoolWorker-3] Task tasks.add[8b9910c2-be8f-42cc-9190-34bed2addcef] succeeded in 0.003176653999616974s: 102
[2017-10-07 17:22:48,067: INFO/MainProcess] Received task: tasks.add[2b36858c-90cb-4da7-8000-de877c63f546]  
[2017-10-07 17:22:48,070: INFO/ForkPoolWorker-4] Task tasks.add[2b36858c-90cb-4da7-8000-de877c63f546] succeeded in 0.0010088269991683774s: 119
[2017-10-07 17:26:26,148: INFO/MainProcess] Received task: tasks.add[7281b2da-636e-4ce9-8a26-19247db674dc]  
[2017-10-07 17:26:26,149: INFO/ForkPoolWorker-3] Task tasks.add[7281b2da-636e-4ce9-8a26-19247db674dc] succeeded in 0.0003721799985214602s: 119
[2017-10-07 17:30:25,885: INFO/MainProcess] Received task: tasks.add[4e775e36-8fbc-43cc-81dd-f1a9aae74486]  
[2017-10-07 17:30:25,886: INFO/ForkPoolWorker-4] Task tasks.add[4e775e36-8fbc-43cc-81dd-f1a9aae74486] succeeded in 0.0003497320012684213s: 100100

```

这些任务我们在`backend` 可以看到，只需要在`redis`的数据库`2`中查看，我们可以看到`46a67c8f-d699-412d-8647-cfa700830cd2` 在redis中的结果。

```shell
vinct@vinct:~/Documents/pyhome/learn$ redis-cli
127.0.0.1:6379> select 2
OK
127.0.0.1:6379[2]> keys *
1) "celery-task-meta-46a67c8f-d699-412d-8647-cfa700830cd2"
2) "celery-task-meta-4e775e36-8fbc-43cc-81dd-f1a9aae74486"
3) "celery-task-meta-2b36858c-90cb-4da7-8000-de877c63f546"
4) "celery-task-meta-7281b2da-636e-4ce9-8a26-19247db674dc"
5) "celery-task-meta-8b9910c2-be8f-42cc-9190-34bed2addcef"
127.0.0.1:6379[2]> get celery-task-meta-46a67c8f-d699-412d-8647-cfa700830cd2
"{\"children\": [], \"traceback\": null, \"result\": 11, \"task_id\": \"46a67c8f-d699-412d-8647-cfa700830cd2\", \"status\": \"SUCCESS\"}"
127.0.0.1:6379[2]> 
```

> 小结
>
> 分布式消息队列celery，使用非常简单，只要了解它的工作原理，基本不会出错，进一步使用我会继续更新。 
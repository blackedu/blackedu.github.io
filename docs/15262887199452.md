---
title: 逻辑斯特回归
tags: 
- 数学
date: 2017-05-20
category: 编程
---

## 逻辑斯特回归

> 上一篇博客整理完了多元线性回归，本次在此基础上来整理广义的线性回归，并介绍具有代表型的逻辑斯特回归。
>
> 逻辑斯特回归虽然有回归二字，其实是一种二分类。

<!--more-->

### 广义线性回归

线性函数$y = \vec w ^ T x + b$ 对线性函数做一个简单处理
$$
g(y) =  \vec w ^ T x + b
$$
于是得到广义线性函数：
$$
y = g^{-1} ( \vec w ^ T x + b)
$$
其中$g(\cdot)$ 单调可微函数



### 对数几率回归

考虑二分类问题$y \in \{ 0, 1\}$ ,而线性预测值为$z = \vec w ^ T x + b$  是实数，于是将$z$ 转换为 0或1.最简单的就是单位阶跃函数，由于单位阶跃函数并不是连续函数，于是使用$Sigmod$  函数代替
$$
y = \frac{1}{1 + \mathbf{e}^{-z}}
$$
用$y$ 表示$z$ 可以得出：
$$
z = \ln \frac{y}{1 - y} = \vec w ^ T x + b
$$


若将$y$ 视为样本$x$ 正例的可能性，$1-y$ 就是对应样本的反例可能性两者的比值称为“几率” 取对数以后称为“对数几率”



### 分类概率的计算

分别使用$P(y=1|x),P(y=0|x)$ 代替 $y, 1-y$ 于是得到：
$$
\ln \frac{P(y=1|x)}{P(y=0|x)} = \vec w ^T x + b
$$

$$
P(y=1|x) = \frac{\exp(\vec w ^T x+ b)}{1 + \exp(\vec w ^T x+ b) } \\
P(y=0|x) = \frac{1}{1 + \exp(\vec w ^T x+ b)}
$$

这样就计算出正反例的概率，当然二分类就属于概率大的一类了。至于计算$\vec w ,x$ 可以参考多元线性回归。
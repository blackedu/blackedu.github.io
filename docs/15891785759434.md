# 理解LSTM网络
刚开始学习神经网络的时候，连基础的CNN都看不懂，更无法理解，它是如何从图片中提取特征的。看到LSTM单元更加懵掉了。如此复杂的结构究竟是怎样被发明出来的？每一步为什么要这么做呢？

本文是一篇详细介绍的基础文章，包含数学公式肯定是在所难免的，要搞清楚这些原理，就必须理解这些公式。

## 循环神经网络
LSTM长短时记忆网络是一种特殊的循环神经网络，所以我们还是从普通的RNN说起。

![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)

网络结构长这个样子，核心的部分就是那个循环结构。对于t时刻的输入$x_t$，输出为$h_t$，状态为$s_t$,于是当前的状态就是：
$$
    s_t = Wx_t+ Us_{t-1}=W_s [s_{t-1}, x_t]
$$

当前的输出为：
$$ h_t = \sigma (V s_t) $$
接下来要做的就是带入样本，训练权重$W_s,V$.

循环神经网络看起来好像输入和输出长度必须相等，实际上不相等也是可以的。例如在文本分类或者情感分析中，只需要最后的输出$h_t$，之前的$h_{t-1}$可以不用计算。

![](https://raw.githubusercontent.com/YZHANG1270/Markdown_pic/master/2018/11/RNN_01/008.jpg)

当然也可以是一个输入多个输出，比如根据图片自动生成对图片的描述，网络结构可以是这样。
![](https://image.jiqizhixin.com/uploads/editor/e2c3d081-b794-4d7c-a426-2855f7ce17e8/1544760757740.png)

普通RNN最大的问题就是每次输入，都是只根据上一次的状态更新当前的状态值，$s_t$只依赖与$s_{t-1}$，每次更新权重都会发生变化，那么对于一个输入长序列，RNN无法记住长序列的信息。理由也是状态无法有选择的更新，没有记忆的功能。直观理解起来就是记性不太好，对于记忆容易遗忘。

现在改造RNN就是希望能记住更长的信息，那至少得有状态存储，有选择更新状态值。于是LSTM就应允而生了。（想要记住长序列的信息也可以在RNN前面接CNN，CNN滤波器的感受视野可以记住一些局部信息，这是题外话了）

## LSTM网络
![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)

到这里我们大致可以想到LSTM会存在哪些结构了。首先对于上一个状态的输入，我们可以选择是否遗忘。也就是当前的状态是否会跟上一个状态有关。其次需要保存一个候选的状态，用于更新状态。对应的叫做遗忘门和记忆存储单元。

![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png)

遗忘门就是对上一个输出，选择遗忘多少。$f_t$是$\sigma$函数的输出，在[0,1]上，0表示完全遗忘，1表示不遗忘。

![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png)

$i_t$是输入值被$\sigma$函数处理以后用于更新候选状态，$ \tilde{C_t}$ 是候选的状态值。接下来就要更新当前的状态值$C_t$了

![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png)

当前状态$C_t$取决于对上一个状态的遗忘和候选状态单元的值。

![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png)

更新完当前的状态值就可以计算输出了。这里的输出为$h_t$.总结起来一共做了三次$\sigma$处理和两次$\tanh$处理。两条贯穿整个节点的横线，上面那条是更新当前状态，下面是更新输出结果。

单从理解的角度看，其实并不难理解，无非就是这4个步骤的计算，如果站在设计者的角度想，那确实难度很大，要设计出这样的单元结构是一件从0到1的事情，至于LSTM出现很多的变种，无非是从1到多的问题。

## 致谢
感谢 [Hochreiter & Schmidhuber 1997](http://www.bioinf.jku.at/publications/older/2604.pdf)的发明； 以及[Colah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)的blog，非常详细通俗的博客文章。文章的配图来自Colah的博客和机器之心。


# 谈谈曾经挖的一个坑
曾经也是一个挖坑少年😁，现在发生了一点点改变。这里分享一个并不太光彩的小故事，也是我以前对技术原理掌握不深导致的，说起来挺惭愧的。

我在某公司做了医疗模型，第一个版本是风险评估的，本质上是一个文本分类问题。这个做得算是比较成功的，最终也取得了比较好的效果。我们在此基础上提出了第二个版本的优化，不仅要给出风险级别，还要给出评级的原因，相当于把这个级别对应的恶性特征词识别出来。这个问题就是实体识别了，我们调研了实体识别的一些主流方法，BiLSTM+CRF，或者Bert+CRF。其实到这里还没有问题，下面就是坑了。

其实不用条件随机场（CRF）肯定也是可以的，参考了一些论文发现用softmax解码不仅效率高，而且在标签多的情况下不会差。“哎，我大E了！”。当时并没有理解CRF的原理，通过实验我发现，最后接了一层CRF确实也没有多大提升，基本差不多，于是更相信了用softmax解码。

通过分析错误的数据，发现预测的标签出现了不是以“B-X”开头的😩，而且最后接了CRF还是出现了这种情况。难道数数据不够，模型没有学到这个特征吗？当时就是这么天真。

现在回头整理一下当时的问题：
1. 出现了标签不是以“B-X”开头的情况，是没有使用CRF进行解码。模型在预测的时候需要使用**维特比算法进行解码，保证标签之间的约束关系**。
2. 我们用了CRF为什么还是标签明显错误的情况。那是因为用得有问题，模型的最后一层接CRF层，只是建模了**特征转移矩阵**，并没有改变模型的输出，所有不会发生改变。

没有引入CRF解码的模型，本质上就是Token Classification的问题，用了softmax解码，相当于假设了标签是相互独立的。既然标签是独立的，那出现什么标签组合都可能了[流下了天真的眼泪].

有时候挖坑不可怕，可怕的是挖坑的时候自己并不知道，自以为是的坑最坑。对于技术的掌握千万不能一知半解，否则一个小细节翻车会很严重，耗子尾汁，好好反思。
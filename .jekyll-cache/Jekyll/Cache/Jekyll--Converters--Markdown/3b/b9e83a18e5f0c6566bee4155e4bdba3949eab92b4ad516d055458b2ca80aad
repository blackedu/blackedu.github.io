I"<p>上次完成了“AI版对穿肠”，使用了UniLM模型，权重采用albert作为初始化权重。相当于把对联模型当成一般的seq2seq的结构，实际上对联的模型的输入和输出是等长的，也可以看成是<strong>序列标注问题，只不过标签类别是整个词库</strong>。也就是说可以在Bert的输出层接一个与词库维度相同的密集层就可以了，这不正是 Masked Language Model吗。</p>
:ET